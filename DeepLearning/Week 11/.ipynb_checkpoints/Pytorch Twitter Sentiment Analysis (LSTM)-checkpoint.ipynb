{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4385,
     "status": "ok",
     "timestamp": 1558384086491,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "oDbbUorDjpFA",
    "outputId": "e90e6d73-076b-4694-e199-df0858a23b94"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Matplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# Word2vec\n",
    "import gensim\n",
    "\n",
    "# Utility\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FGfrIqXdjgKF"
   },
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17560,
     "status": "ok",
     "timestamp": 1558384099695,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "968XyJGwhUFT",
    "outputId": "e6ed10fe-1653-4377-a0be-8d9657643466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-20 20:28:07--  http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
      "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
      "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip [following]\n",
      "--2019-05-20 20:28:13--  https://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
      "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 81363704 (78M) [application/zip]\n",
      "Saving to: ‘trainingandtestdata.zip’\n",
      "\n",
      "trainingandtestdata 100%[===================>]  77.59M  19.7MB/s    in 4.8s    \n",
      "\n",
      "2019-05-20 20:28:18 (16.1 MB/s) - ‘trainingandtestdata.zip’ saved [81363704/81363704]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22381,
     "status": "ok",
     "timestamp": 1558384104555,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "jt629cqbhbUN",
    "outputId": "dee5fbd6-8134-4324-b23b-61661e067feb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  trainingandtestdata.zip\n",
      "  inflating: testdata.manual.2009.06.14.csv  \n",
      "  inflating: training.1600000.processed.noemoticon.csv  \n"
     ]
    }
   ],
   "source": [
    "!unzip trainingandtestdata.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzUFF3Lhjji3"
   },
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1Y6WpmDirov"
   },
   "outputs": [],
   "source": [
    "# DATASET\n",
    "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "# WORD2VEC \n",
    "W2V_SIZE = 300\n",
    "W2V_WINDOW = 7\n",
    "W2V_EPOCH = 32\n",
    "W2V_MIN_COUNT = 10\n",
    "\n",
    "# KERAS\n",
    "SEQUENCE_LENGTH = 300\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# SENTIMENT\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3TxGI1hOixHM"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", encoding = DATASET_ENCODING , names = DATASET_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26968,
     "status": "ok",
     "timestamp": 1558384109182,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "czRFLQCPi5mm",
    "outputId": "561fb91b-f878-417b-dcd2-b28677ad9ffc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  ...                                               text\n",
       "0       0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1       0  ...  is upset that he can't update his Facebook by ...\n",
       "2       0  ...  @Kenichan I dived many times for the ball. Man...\n",
       "3       0  ...    my whole body feels itchy and like its on fire \n",
       "4       0  ...  @nationwideclass no, it's not behaving at all....\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26945,
     "status": "ok",
     "timestamp": 1558384109184,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "84O4nKm0jLTu",
    "outputId": "f28867f4-0b4f-4077-85ab-974d105dd3ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcRTbj2VkME9"
   },
   "outputs": [],
   "source": [
    "# decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"}\n",
    "decode_map = {0: \"NEGATIVE\", 4: \"POSITIVE\"}\n",
    "def decode_sentiment(label):\n",
    "    return decode_map[int(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27531,
     "status": "ok",
     "timestamp": 1558384109788,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "TJ1hPmSkkpaQ",
    "outputId": "36309115-a340-4735-cb24-062db45a8588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 603 ms, sys: 3.65 ms, total: 606 ms\n",
      "Wall time: 608 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.target = df.target.apply(lambda x: decode_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28138,
     "status": "ok",
     "timestamp": 1558384110426,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "iolehWWnkvmL",
    "outputId": "a5389380-f560-4af1-d431-e21949d6baf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Dataset labels distribuition')"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAE/CAYAAAD7Z5/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVLnDGySJEmd+/95zONuqZeqvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_cnt = Counter(df.target)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(target_cnt.keys(), target_cnt.values())\n",
    "plt.title(\"Dataset labels distribuition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T7fTzX6clsLv"
   },
   "source": [
    "## Pre-Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28120,
     "status": "ok",
     "timestamp": 1558384110428,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "Ucn2hpgKn3g9",
    "outputId": "cfd5ef8c-3a95-4a99-fd59-4509dee31925"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3f7H-5X1k_x5"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# Happy Emoticons\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', ';D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])\n",
    " \n",
    "# Sad Emoticons\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])\n",
    " \n",
    "# all emoticons (happy + sad)\n",
    "emoticons = emoticons_happy.union(emoticons_sad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NKh3MTRKnZ7h"
   },
   "outputs": [],
   "source": [
    "def preprocess(text, stem=False):\n",
    "  # remove stock market tickers like $GE\n",
    "  text = re.sub(r'\\$\\w*', '', text)\n",
    " \n",
    "  # remove old style retweet text \"RT\"\n",
    "  text = re.sub(r'^RT[\\s]+', '', text)\n",
    "\n",
    "  # remove hyperlinks\n",
    "  text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "  # remove hashtags\n",
    "  # only removing the hash # sign from the word\n",
    "  text = re.sub(r'#', '', text)\n",
    "\n",
    "  # Other cleaning measures\n",
    "  text = text.replace(' ,', ',')\n",
    "  text = text.replace(' .', '.')\n",
    "  text = text.replace(\"\\' \", \"'\")\n",
    "  text = text.replace(\" \\'\", \"'\")\n",
    "\n",
    "  # tokenize tweets\n",
    "  tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "  text_tokens = tokenizer.tokenize(text)\n",
    "\n",
    "  text_clean = []    \n",
    "  for word in text_tokens:\n",
    "      if (word not in stop_words and # remove stopwords\n",
    "            word not in emoticons and # remove emoticons\n",
    "              word not in string.punctuation and\n",
    "                 word not in \"...\"): # remove punctuation\n",
    "          stem_word = stemmer.stem(word) # stemming word\n",
    "          text_clean.append(stem_word)\n",
    "\n",
    "  return \" \".join(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28102,
     "status": "ok",
     "timestamp": 1558384110440,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "vTau5nzP_FGl",
    "outputId": "9203ad66-2367-496e-ff10-c2a0750130e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Text: is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\n",
      "cleaned Text: upset can't updat facebook text might cri result school today also blah\n"
     ]
    }
   ],
   "source": [
    "text = df.loc[df.index == 1, 'text'].values[0]\n",
    "\n",
    "print(\"Initial Text:\", text)\n",
    "print(\"cleaned Text:\", preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 342466,
     "status": "ok",
     "timestamp": 1558384424837,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "Y6OW1QMtoFFc",
    "outputId": "14ad0dd3-f54e-45e0-b319-29042e44acf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 8s, sys: 5.43 s, total: 5min 14s\n",
      "Wall time: 5min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.text = df.text.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 342459,
     "status": "ok",
     "timestamp": 1558384424847,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "wpbFoAp9oMSr",
    "outputId": "193ac82b-9772-45e9-f554-eecb44dd83bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>awww that bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>upset can't updat facebook text might cri resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>dive mani time ball manag save 50 rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>behav i'm mad can't see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  ...                                               text\n",
       "0  NEGATIVE  ...  awww that bummer shoulda got david carr third day\n",
       "1  NEGATIVE  ...  upset can't updat facebook text might cri resu...\n",
       "2  NEGATIVE  ...    dive mani time ball manag save 50 rest go bound\n",
       "3  NEGATIVE  ...                    whole bodi feel itchi like fire\n",
       "4  NEGATIVE  ...                            behav i'm mad can't see\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dzj1KFwdOTSV"
   },
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 342444,
     "status": "ok",
     "timestamp": 1558384424850,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "GTQvxFa54SCM",
    "outputId": "ceb2d124-fb69-42fc-ad20-617a78c07a5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 342432,
     "status": "ok",
     "timestamp": 1558384424853,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "jCFVxD6-D2fC",
    "outputId": "f41b421a-7dce-4b8a-c223-9755e68a331c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 210 ms, sys: 5.97 ms, total: 216 ms\n",
      "Wall time: 217 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# documents = [_text.split() for _text in df.text]\n",
    "documents = [_text for _text in df.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 342427,
     "status": "ok",
     "timestamp": 1558384424860,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "B82ZAdf3PkWQ",
    "outputId": "4f56b632-8043-47ac-c2fc-5472bf5ec91f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awww that bummer shoulda got david carr third day',\n",
       " \"upset can't updat facebook text might cri result school today also blah\",\n",
       " 'dive mani time ball manag save 50 rest go bound',\n",
       " 'whole bodi feel itchi like fire',\n",
       " \"behav i'm mad can't see\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 343809,
     "status": "ok",
     "timestamp": 1558384426255,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "49AbioErP7-5",
    "outputId": "a2388793-f597-4f1d-c397-efb15af0f063"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awww',\n",
       " 'that',\n",
       " 'bummer',\n",
       " 'shoulda',\n",
       " 'got',\n",
       " 'david',\n",
       " 'carr',\n",
       " 'third',\n",
       " 'day',\n",
       " 'upset']"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of all available string characters\n",
    "all_documents = ' '.join(documents)\n",
    "all_documents = all_documents.split()\n",
    "all_documents[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VRRBiXLHyCFQ"
   },
   "source": [
    "## Encoding the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eVNdgCdlxbYY"
   },
   "outputs": [],
   "source": [
    "# feel free to use this import \n",
    "from collections import Counter\n",
    "\n",
    "## Build a dictionary that maps words to integers\n",
    "counts = Counter(all_documents) # gets each words as keys, and their no of occurence as values\n",
    "vocab = sorted(counts, key=counts.get, reverse=True) # store each key in a sorted list\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)} # give each key a unique value starting from 1\n",
    "\n",
    "## use the dict to tokenize each review in reviews_split\n",
    "## store the tokenized reviews in reviews_ints\n",
    "documents_ints = []\n",
    "for sentence in documents: # iterate through each reviews\n",
    "    documents_ints.append([vocab_to_int[word] for word in sentence.split()]) # append list containing each characters for each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 353628,
     "status": "ok",
     "timestamp": 1558384436090,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "aiXoon2_2n_Q",
    "outputId": "3b5c0058-8774-4bd8-b0cc-5e7c54c9071e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words:  285335\n",
      "\n",
      "Tokenized review: \n",
      " [[246, 49, 1062, 3125, 11, 722, 7644, 1722, 4]]\n"
     ]
    }
   ],
   "source": [
    "# stats about vocabulary\n",
    "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
    "print()\n",
    "\n",
    "# print tokens in first review\n",
    "print('Tokenized review: \\n', documents_ints[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRaxNkcw4HKX"
   },
   "source": [
    "## Encoding Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 353559,
     "status": "ok",
     "timestamp": 1558384436091,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "PoyWA3Vr4D1B",
    "outputId": "b5c5d5b3-0aa2-4cc9-eda9-d1416a5573c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1=positive, 0=negative label conversion\n",
    "labels = df.target.tolist()\n",
    "encoded_labels = np.array([1 if label == 'POSITIVE' else 0 for label in labels])\n",
    "encoded_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QaxkxvVF-g-x"
   },
   "source": [
    "## Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 353745,
     "status": "ok",
     "timestamp": 1558384436529,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "q3DyxLLJ-b05",
    "outputId": "5630d99d-c15a-4948-800b-7d07a7a5beac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews: 7110\n",
      "Maximum review length: 302\n"
     ]
    }
   ],
   "source": [
    "# outlier review stats\n",
    "documents_lens = Counter([len(x) for x in documents_ints]) # get a list of the length of each tweet/document as pass into counter\n",
    "print(\"Zero-length reviews: {}\".format(documents_lens[0])) # print tweets with 0 length \n",
    "print(\"Maximum review length: {}\".format(max(documents_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 354032,
     "status": "ok",
     "timestamp": 1558384437101,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "JWrnaL4N-6lI",
    "outputId": "4c9c7f51-dec2-4fb9-f359-5a65ae8b2942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews before removing outliers:  1600000\n",
      "Number of reviews after removing outliers:  1592890\n"
     ]
    }
   ],
   "source": [
    "# remove any reviews with zero length from the reviews_ints list and their corresponding label in encoded_labels\n",
    "print('Number of reviews before removing outliers: ', len(documents_ints))\n",
    "\n",
    "## remove any reviews/labels with zero length from the reviews_ints list.\n",
    "\n",
    "# get indices of any reviews with length 0\n",
    "non_zero_idx = [ii for ii, documents in enumerate(documents_ints) if len(documents) != 0]\n",
    "\n",
    "# remove 0-length reviews and their labels\n",
    "documents_ints = [documents_ints[ii] for ii in non_zero_idx]\n",
    "encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])\n",
    "\n",
    "print('Number of reviews after removing outliers: ', len(documents_ints))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7cn_wysQsi6l"
   },
   "source": [
    "## Padding sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SGIPrpI-qzR_"
   },
   "outputs": [],
   "source": [
    "def pad_features(documents_ints, seq_length):\n",
    "    ''' Return features of documents_ints, where each review is padded with 0's \n",
    "        or truncated to the input seq_length.\n",
    "    '''\n",
    "    \n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(documents_ints), seq_length), dtype=int)\n",
    "\n",
    "    # for each document, I grab that document and \n",
    "    for i, row in enumerate(documents_ints):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 358268,
     "status": "ok",
     "timestamp": 1558384441917,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "gwD4mXz80MAs",
    "outputId": "91f394a8-a02e-4c33-ecf5-321a9a2cdc00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16454   114   234  2633   234  2580    16  4821  1715   114]\n",
      " [  583   212   354    11   338  3126   813    10    35    80]\n",
      " [    0     0     0     0     0     0     0   867   287     6]\n",
      " [    0     0     0     0     0     0     0     0    30   147]\n",
      " [    0     0     0   329   725   619  2747    15    10   328]\n",
      " [    0     0     0   126   381  4977   506   430  8561  5150]\n",
      " [    0     0  2286   184   864   118   346    33   219    16]\n",
      " [  307    51   494  1228   180   307  1048    17 16455   107]\n",
      " [    0     0     0     0     0     0     0     0     0  5212]\n",
      " [    0     0    18   410   462   197    59  8317   867    10]]\n"
     ]
    }
   ],
   "source": [
    "# Test your implementation!\n",
    "\n",
    "seq_length = 200\n",
    "\n",
    "features = pad_features(documents_ints, seq_length=seq_length)\n",
    "\n",
    "## test statements - do not change - ##\n",
    "assert len(features)==len(documents_ints), \"Your features should have as many rows as reviews.\"\n",
    "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# print first 10 values of the first 30 batches \n",
    "print(features[100:110,190:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 358049,
     "status": "ok",
     "timestamp": 1558384441919,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "GH6jPtWq8vET",
    "outputId": "7b2caebe-1666-4312-afe3-be36c092257b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1592890, 200) (1592890,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape, encoded_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_fibxshv6oOp"
   },
   "source": [
    "## Training, Validation, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 357643,
     "status": "ok",
     "timestamp": 1558384441920,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "vWzJw-KP13B2",
    "outputId": "6a2c712b-128d-42ff-f985-00ed6065ecee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(1274312, 200) \n",
      "Validation set: \t(159289, 200) \n",
      "Test set: \t\t(159289, 200)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(features)*0.8)\n",
    "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
    "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GfuuCX-y9Oq6"
   },
   "source": [
    "## DataLoaders and Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0H0G1-sg9HXZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "\n",
    "# make sure the SHUFFLE your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 358315,
     "status": "ok",
     "timestamp": 1558384443449,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "Kl3Ts4f09c-m",
    "outputId": "747664d0-03f5-4d4a-d7f8-7cc162c12e88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 200])\n",
      "Sample input: \n",
      " tensor([[     0,      0,      0,  ...,    913,   3923,   1133],\n",
      "        [     0,      0,      0,  ...,      3,     15,    211],\n",
      "        [     0,      0,      0,  ...,      0,   5591, 172118],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   1379,      8,    280],\n",
      "        [     0,      0,      0,  ..., 214037,   3631,  30489],\n",
      "        [     0,      0,      0,  ...,      0,   1540,     98]])\n",
      "\n",
      "Sample label size:  torch.Size([50])\n",
      "Sample label: \n",
      " tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0])\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tSKAwj3L9jzX"
   },
   "source": [
    "## Sentiment Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pHhWXDNx9qxL"
   },
   "source": [
    "The layers are as follows:\n",
    "1. An [embedding layer](https://pytorch.org/docs/stable/nn.html#embedding) that converts our word tokens (integers) into embeddings of a specific size.\n",
    "2. An [LSTM layer](https://pytorch.org/docs/stable/nn.html#lstm) defined by a hidden_state size and number of layers\n",
    "3. A fully-connected output layer that maps the LSTM layer outputs to a desired output_size\n",
    "4. A sigmoid activation layer which turns all outputs into a value 0-1; return **only the last sigmoid output** as the output of this network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 357589,
     "status": "ok",
     "timestamp": 1558384443452,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "BEHspXqc9gQ3",
    "outputId": "fedb21ea-f38c-40a4-b909-4db578382df9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXIjKGCo96Ba"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g_YPXC3fAPeM"
   },
   "source": [
    "## Instantiate the network\n",
    "\n",
    "Here, we'll instantiate the network. First up, defining the hyperparameters.\n",
    "\n",
    "* `vocab_size`: Size of our vocabulary or the range of values for our input, word tokens.\n",
    "* `output_size`: Size of our desired output; the number of class scores we want to output (pos/neg).\n",
    "* `embedding_dim`: Number of columns in the embedding lookup table; size of our embeddings.\n",
    "* `hidden_dim`: Number of units in the hidden layers of our LSTM cells. Usually larger is better performance wise. Common values are 128, 256, 512, etc.\n",
    "* `n_layers`: Number of LSTM layers in the network. Typically between 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 358132,
     "status": "ok",
     "timestamp": 1558384444872,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "WbUAXG1h_5al",
    "outputId": "ddf0b351-4dac-4e69-df46-e1edcf35ea36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(285336, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2yi3cIN-AoTZ"
   },
   "source": [
    "## Training\n",
    "\n",
    ">We'll also be using a new kind of cross entropy loss, which is designed to work with a single Sigmoid output. [BCELoss](https://pytorch.org/docs/stable/nn.html#bceloss), or **Binary Cross Entropy Loss**, applies cross entropy loss to a single value between 0 and 1.\n",
    "​\n",
    "We also have some data and training hyparameters:\n",
    "​\n",
    "* `lr`: Learning rate for our optimizer.\n",
    "* `epochs`: Number of times to iterate through the training dataset.\n",
    "* `clip`: The maximum gradient value to clip at (to prevent exploding gradients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGM-iHnAAhLl"
   },
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 9010
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2912003,
     "status": "error",
     "timestamp": 1558397447615,
     "user": {
      "displayName": "Stanley Dukor",
      "photoUrl": "https://lh5.googleusercontent.com/-VbeE7J7Td0w/AAAAAAAAAAI/AAAAAAAACU8/jUTZBfWCj4o/s64/photo.jpg",
      "userId": "06936529354896853748"
     },
     "user_tz": 0
    },
    "id": "ulpHnigXAwh1",
    "outputId": "f63c18bb-e0ae-4e91-f8e0-357cdf922dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 100... Loss: 0.621287... Val Loss: 0.749920\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 200... Loss: 0.598469... Val Loss: 0.821727\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 300... Loss: 0.574918... Val Loss: 0.753742\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 400... Loss: 0.551365... Val Loss: 0.789799\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 500... Loss: 0.475995... Val Loss: 0.668666\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 600... Loss: 0.348776... Val Loss: 0.765271\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 700... Loss: 0.544445... Val Loss: 0.735452\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 800... Loss: 0.464487... Val Loss: 0.647839\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 900... Loss: 0.469831... Val Loss: 0.718391\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 1000... Loss: 0.497880... Val Loss: 0.751245\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 1100... Loss: 0.502838... Val Loss: 0.795035\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 1200... Loss: 0.491171... Val Loss: 0.649865\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 1300... Loss: 0.499596... Val Loss: 0.808145\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 1400... Loss: 0.439501... Val Loss: 0.606044\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 1500... Loss: 0.436890... Val Loss: 0.722216\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 1600... Loss: 0.458638... Val Loss: 0.709313\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 1700... Loss: 0.513332... Val Loss: 0.730167\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 1800... Loss: 0.478650... Val Loss: 0.641313\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 1900... Loss: 0.444811... Val Loss: 0.659764\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 2000... Loss: 0.450256... Val Loss: 0.674944\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 2100... Loss: 0.620044... Val Loss: 0.648006\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 2200... Loss: 0.361343... Val Loss: 0.717142\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 2300... Loss: 0.443305... Val Loss: 0.709358\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 2400... Loss: 0.496834... Val Loss: 0.628151\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 2500... Loss: 0.384503... Val Loss: 0.626068\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 2600... Loss: 0.570892... Val Loss: 0.759538\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 2700... Loss: 0.408547... Val Loss: 0.610970\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 2800... Loss: 0.477903... Val Loss: 0.646276\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 2900... Loss: 0.408300... Val Loss: 0.671801\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 3000... Loss: 0.622362... Val Loss: 0.629900\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 3100... Loss: 0.497826... Val Loss: 0.611199\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 3200... Loss: 0.549674... Val Loss: 0.641969\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 3300... Loss: 0.486419... Val Loss: 0.711392\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 3400... Loss: 0.381150... Val Loss: 0.677306\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 3500... Loss: 0.359025... Val Loss: 0.644634\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 3600... Loss: 0.357501... Val Loss: 0.588636\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 3700... Loss: 0.583420... Val Loss: 0.645394\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 3800... Loss: 0.433382... Val Loss: 0.644068\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 3900... Loss: 0.488704... Val Loss: 0.666238\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 4000... Loss: 0.315655... Val Loss: 0.652081\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 4100... Loss: 0.365120... Val Loss: 0.687054\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 4200... Loss: 0.499354... Val Loss: 0.674985\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 4300... Loss: 0.529206... Val Loss: 0.615803\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 4400... Loss: 0.590169... Val Loss: 0.665147\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 4500... Loss: 0.409253... Val Loss: 0.724573\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 4600... Loss: 0.527783... Val Loss: 0.671227\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 4700... Loss: 0.439335... Val Loss: 0.636348\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 4800... Loss: 0.382298... Val Loss: 0.610892\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 4900... Loss: 0.434142... Val Loss: 0.645226\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 5000... Loss: 0.500203... Val Loss: 0.643008\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 5100... Loss: 0.672909... Val Loss: 0.695309\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 5200... Loss: 0.517736... Val Loss: 0.614847\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 5300... Loss: 0.409297... Val Loss: 0.627748\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 5400... Loss: 0.290830... Val Loss: 0.668546\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 5500... Loss: 0.457235... Val Loss: 0.639432\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 5600... Loss: 0.493204... Val Loss: 0.617877\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 5700... Loss: 0.363373... Val Loss: 0.664488\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 5800... Loss: 0.493567... Val Loss: 0.588399\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 5900... Loss: 0.493279... Val Loss: 0.618241\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 6000... Loss: 0.460052... Val Loss: 0.658811\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 6100... Loss: 0.386932... Val Loss: 0.705161\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 6200... Loss: 0.478365... Val Loss: 0.634220\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 6300... Loss: 0.397992... Val Loss: 0.651367\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 6400... Loss: 0.460973... Val Loss: 0.727081\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 6500... Loss: 0.451729... Val Loss: 0.645711\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 6600... Loss: 0.488874... Val Loss: 0.608192\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 6700... Loss: 0.378998... Val Loss: 0.659149\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 6800... Loss: 0.354449... Val Loss: 0.643149\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 6900... Loss: 0.339973... Val Loss: 0.598620\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 7000... Loss: 0.375968... Val Loss: 0.647390\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 7100... Loss: 0.397949... Val Loss: 0.671935\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 7200... Loss: 0.460363... Val Loss: 0.654384\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 7300... Loss: 0.419444... Val Loss: 0.666283\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 7400... Loss: 0.441812... Val Loss: 0.620913\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 7500... Loss: 0.515187... Val Loss: 0.640568\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 7600... Loss: 0.425186... Val Loss: 0.665476\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 7700... Loss: 0.466445... Val Loss: 0.687092\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 7800... Loss: 0.409113... Val Loss: 0.635413\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 7900... Loss: 0.447371... Val Loss: 0.677157\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 8000... Loss: 0.607598... Val Loss: 0.659663\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 8100... Loss: 0.589941... Val Loss: 0.653837\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 8200... Loss: 0.502763... Val Loss: 0.621763\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 8300... Loss: 0.366599... Val Loss: 0.606247\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 8400... Loss: 0.461509... Val Loss: 0.613589\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 8500... Loss: 0.483461... Val Loss: 0.648857\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 8600... Loss: 0.414953... Val Loss: 0.597670\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 8700... Loss: 0.422813... Val Loss: 0.688404\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 8800... Loss: 0.334400... Val Loss: 0.650185\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 8900... Loss: 0.472524... Val Loss: 0.692062\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 9000... Loss: 0.436887... Val Loss: 0.621294\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 9100... Loss: 0.548164... Val Loss: 0.642268\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 9200... Loss: 0.502404... Val Loss: 0.630220\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 9300... Loss: 0.423628... Val Loss: 0.609598\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 9400... Loss: 0.472477... Val Loss: 0.641348\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 9500... Loss: 0.515945... Val Loss: 0.610891\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 9600... Loss: 0.498970... Val Loss: 0.704476\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 9700... Loss: 0.507549... Val Loss: 0.624342\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 9800... Loss: 0.540592... Val Loss: 0.640961\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 9900... Loss: 0.416555... Val Loss: 0.634268\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 10000... Loss: 0.554006... Val Loss: 0.693445\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 10100... Loss: 0.592168... Val Loss: 0.639603\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 10200... Loss: 0.387566... Val Loss: 0.622446\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 10300... Loss: 0.376538... Val Loss: 0.670791\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 10400... Loss: 0.377492... Val Loss: 0.653791\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 10500... Loss: 0.386951... Val Loss: 0.621917\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 10600... Loss: 0.417438... Val Loss: 0.683369\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 10700... Loss: 0.423543... Val Loss: 0.681968\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 10800... Loss: 0.396484... Val Loss: 0.662706\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 10900... Loss: 0.508162... Val Loss: 0.645332\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 11000... Loss: 0.396392... Val Loss: 0.655045\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 11100... Loss: 0.531571... Val Loss: 0.596716\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 11200... Loss: 0.439531... Val Loss: 0.622514\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 11300... Loss: 0.372649... Val Loss: 0.661789\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 11400... Loss: 0.473646... Val Loss: 0.672461\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 11500... Loss: 0.446123... Val Loss: 0.619676\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 11600... Loss: 0.571804... Val Loss: 0.629706\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 11700... Loss: 0.317428... Val Loss: 0.662030\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 11800... Loss: 0.462063... Val Loss: 0.644788\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 11900... Loss: 0.407842... Val Loss: 0.682231\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 12000... Loss: 0.434220... Val Loss: 0.645467\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 12100... Loss: 0.505453... Val Loss: 0.613812\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 12200... Loss: 0.418387... Val Loss: 0.617691\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 12300... Loss: 0.469557... Val Loss: 0.735747\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 12400... Loss: 0.506709... Val Loss: 0.601986\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 12500... Loss: 0.506897... Val Loss: 0.636232\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 12600... Loss: 0.463690... Val Loss: 0.685079\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 12700... Loss: 0.468017... Val Loss: 0.623188\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 12800... Loss: 0.368903... Val Loss: 0.646873\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 12900... Loss: 0.492194... Val Loss: 0.653882\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 13000... Loss: 0.414885... Val Loss: 0.686861\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 13100... Loss: 0.264092... Val Loss: 0.624863\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 13200... Loss: 0.409526... Val Loss: 0.638773\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 13300... Loss: 0.512355... Val Loss: 0.645613\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 13400... Loss: 0.411089... Val Loss: 0.634617\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 13500... Loss: 0.322254... Val Loss: 0.631517\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 13600... Loss: 0.454419... Val Loss: 0.636465\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 13700... Loss: 0.524776... Val Loss: 0.665025\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 13800... Loss: 0.400911... Val Loss: 0.569652\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 13900... Loss: 0.511845... Val Loss: 0.608763\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 14000... Loss: 0.422497... Val Loss: 0.588594\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 14100... Loss: 0.532818... Val Loss: 0.611063\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 14200... Loss: 0.405446... Val Loss: 0.664610\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 14300... Loss: 0.424381... Val Loss: 0.642668\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 14400... Loss: 0.422386... Val Loss: 0.658699\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 14500... Loss: 0.479481... Val Loss: 0.632144\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 14600... Loss: 0.340285... Val Loss: 0.711829\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 14700... Loss: 0.347716... Val Loss: 0.643501\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 14800... Loss: 0.525364... Val Loss: 0.615652\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 14900... Loss: 0.502270... Val Loss: 0.623670\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 15000... Loss: 0.488815... Val Loss: 0.636874\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 15100... Loss: 0.355172... Val Loss: 0.676737\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 15200... Loss: 0.457078... Val Loss: 0.715877\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 15300... Loss: 0.448175... Val Loss: 0.658812\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 15400... Loss: 0.287561... Val Loss: 0.629031\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 15500... Loss: 0.366344... Val Loss: 0.662923\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 15600... Loss: 0.386085... Val Loss: 0.657964\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 15700... Loss: 0.490602... Val Loss: 0.640389\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 15800... Loss: 0.398838... Val Loss: 0.621340\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 15900... Loss: 0.555295... Val Loss: 0.684266\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 16000... Loss: 0.460863... Val Loss: 0.661670\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 16100... Loss: 0.444635... Val Loss: 0.597044\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 16200... Loss: 0.339205... Val Loss: 0.666798\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 16300... Loss: 0.429866... Val Loss: 0.659043\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 16400... Loss: 0.400633... Val Loss: 0.591205\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 16500... Loss: 0.416158... Val Loss: 0.626201\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 16600... Loss: 0.401340... Val Loss: 0.637646\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 16700... Loss: 0.470126... Val Loss: 0.610899\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 16800... Loss: 0.410670... Val Loss: 0.658738\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 16900... Loss: 0.449645... Val Loss: 0.614104\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 17000... Loss: 0.251558... Val Loss: 0.662181\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 17100... Loss: 0.351696... Val Loss: 0.634718\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 17200... Loss: 0.359186... Val Loss: 0.664419\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 17300... Loss: 0.447432... Val Loss: 0.605154\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 17400... Loss: 0.441744... Val Loss: 0.613755\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 17500... Loss: 0.497558... Val Loss: 0.611631\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 17600... Loss: 0.499491... Val Loss: 0.644401\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 17700... Loss: 0.363693... Val Loss: 0.622532\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 17800... Loss: 0.631238... Val Loss: 0.596034\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 17900... Loss: 0.523404... Val Loss: 0.617454\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 18000... Loss: 0.648712... Val Loss: 0.640306\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 18100... Loss: 0.428142... Val Loss: 0.701642\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 18200... Loss: 0.311935... Val Loss: 0.584788\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 18300... Loss: 0.389530... Val Loss: 0.658244\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 18400... Loss: 0.456822... Val Loss: 0.614768\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 18500... Loss: 0.409434... Val Loss: 0.641873\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 18600... Loss: 0.460759... Val Loss: 0.637416\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 18700... Loss: 0.531963... Val Loss: 0.574896\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 18800... Loss: 0.395516... Val Loss: 0.637185\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 18900... Loss: 0.535086... Val Loss: 0.622347\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 19000... Loss: 0.407717... Val Loss: 0.604353\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 19100... Loss: 0.467580... Val Loss: 0.600080\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 19200... Loss: 0.316535... Val Loss: 0.566671\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 19300... Loss: 0.432087... Val Loss: 0.624535\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 19400... Loss: 0.366808... Val Loss: 0.645127\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 19500... Loss: 0.327468... Val Loss: 0.651890\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 19600... Loss: 0.352486... Val Loss: 0.604397\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 19700... Loss: 0.453368... Val Loss: 0.632981\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 19800... Loss: 0.482624... Val Loss: 0.625635\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 19900... Loss: 0.364868... Val Loss: 0.652494\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 20000... Loss: 0.517470... Val Loss: 0.660797\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 20100... Loss: 0.429616... Val Loss: 0.710737\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 20200... Loss: 0.535363... Val Loss: 0.595036\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 20300... Loss: 0.526970... Val Loss: 0.647363\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 20400... Loss: 0.461796... Val Loss: 0.616015\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 20500... Loss: 0.455144... Val Loss: 0.686332\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 20600... Loss: 0.484517... Val Loss: 0.606172\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 20700... Loss: 0.533170... Val Loss: 0.607218\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 20800... Loss: 0.368363... Val Loss: 0.623950\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 20900... Loss: 0.352097... Val Loss: 0.671480\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 21000... Loss: 0.570343... Val Loss: 0.632443\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 21100... Loss: 0.451974... Val Loss: 0.657802\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 21200... Loss: 0.461142... Val Loss: 0.620502\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 21300... Loss: 0.544162... Val Loss: 0.674246\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 21400... Loss: 0.493002... Val Loss: 0.641024\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 21500... Loss: 0.484069... Val Loss: 0.600039\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 21600... Loss: 0.457571... Val Loss: 0.620740\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 21700... Loss: 0.365365... Val Loss: 0.626563\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 21800... Loss: 0.425662... Val Loss: 0.589446\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 21900... Loss: 0.463012... Val Loss: 0.622652\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 22000... Loss: 0.534811... Val Loss: 0.622189\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 22100... Loss: 0.331216... Val Loss: 0.677735\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 22200... Loss: 0.533738... Val Loss: 0.702725\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 22300... Loss: 0.284496... Val Loss: 0.619734\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 22400... Loss: 0.403711... Val Loss: 0.634593\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 22500... Loss: 0.362110... Val Loss: 0.641806\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 22600... Loss: 0.387932... Val Loss: 0.616767\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 22700... Loss: 0.561272... Val Loss: 0.617742\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 22800... Loss: 0.364929... Val Loss: 0.599044\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 22900... Loss: 0.459309... Val Loss: 0.623957\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 23000... Loss: 0.508190... Val Loss: 0.602952\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 23100... Loss: 0.393701... Val Loss: 0.676829\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 23200... Loss: 0.308549... Val Loss: 0.655522\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 23300... Loss: 0.329985... Val Loss: 0.657292\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 23400... Loss: 0.355470... Val Loss: 0.624519\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 23500... Loss: 0.437614... Val Loss: 0.629554\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 23600... Loss: 0.460806... Val Loss: 0.607478\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 23700... Loss: 0.414583... Val Loss: 0.608433\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 23800... Loss: 0.404576... Val Loss: 0.592649\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 23900... Loss: 0.522413... Val Loss: 0.679963\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 24000... Loss: 0.383878... Val Loss: 0.621234\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 24100... Loss: 0.567499... Val Loss: 0.641061\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 24200... Loss: 0.397056... Val Loss: 0.679310\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 24300... Loss: 0.592036... Val Loss: 0.600952\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 24400... Loss: 0.329760... Val Loss: 0.626589\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 24500... Loss: 0.526074... Val Loss: 0.685624\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 24600... Loss: 0.386349... Val Loss: 0.614181\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 24700... Loss: 0.437323... Val Loss: 0.610751\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 24800... Loss: 0.460001... Val Loss: 0.647589\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 24900... Loss: 0.449923... Val Loss: 0.600551\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 25000... Loss: 0.474035... Val Loss: 0.682682\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 25100... Loss: 0.311738... Val Loss: 0.644800\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 25200... Loss: 0.398721... Val Loss: 0.612762\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 25300... Loss: 0.236678... Val Loss: 0.638756\n",
      "Validation - Input Shape Issue: torch.Size([39, 200])\n",
      "Epoch: 1/4... Step: 25400... Loss: 0.357800... Val Loss: 0.632582\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-9611bb063d54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# get the output from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# calculate the loss and perform backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-6f96ba14fffe>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# embeddings and lstm_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# stack up lstm outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         self.check_hidden_size(hidden[0], expected_hidden_size,\n\u001b[0;32m--> 494\u001b[0;31m                                'Expected hidden[0] size {}, got {}')\n\u001b[0m\u001b[1;32m    495\u001b[0m         self.check_hidden_size(hidden[1], expected_hidden_size,\n\u001b[1;32m    496\u001b[0m                                'Expected hidden[1] size {}, got {}')\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# type: (Tensor, Tuple[int, int, int], str) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (2, 12, 256), got (2, 50, 256)"
     ]
    }
   ],
   "source": [
    "# training params\n",
    "\n",
    "epochs = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "              \n",
    "                if( (inputs.shape[0],inputs.shape[1]) != (batch_size,seq_length) ):\n",
    "                  print(\"Validation - Input Shape Issue:\",inputs.shape)\n",
    "                  continue\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dqcQgCG_A9-3"
   },
   "outputs": [],
   "source": [
    "# Get test data loss and accuracy\n",
    "\n",
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "\n",
    "# init hidden state\n",
    "h = net.init_hidden(batch_size)\n",
    "\n",
    "net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "    \n",
    "    if( (inputs.shape[0],inputs.shape[1]) != (batch_size,seq_length) ):\n",
    "                  print(\"Validation - Input Shape Issue:\",inputs.shape)\n",
    "                  continue\n",
    "          \n",
    "    # Creating new variables for the hidden state, otherwise\n",
    "    # we'd backprop through the entire training history\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output, h = net(inputs, h)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eD37nZA4Vvxk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Twitter Sentiment Analysis (LSTM).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
